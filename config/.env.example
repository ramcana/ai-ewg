# AI Enrichment System Environment Variables
# Copy this to .env and fill in your values

# ========================================
# Hugging Face Configuration
# ========================================
# Get your token from: https://huggingface.co/settings/tokens
# Required for pyannote.audio speaker diarization
# Must accept model terms at: https://huggingface.co/pyannote/speaker-diarization
HF_TOKEN=your_huggingface_token_here

# ========================================
# Ollama Configuration (Local LLM)
# ========================================
# Ollama API endpoint (default: localhost)
OLLAMA_URL=http://localhost:11434

# Model to use for entity extraction
# Options: mistral, qwen2, llama3, phi3
OLLAMA_MODEL=mistral

# ========================================
# Processing Configuration
# ========================================
# Device for GPU acceleration: cuda or cpu
DIARIZE_DEVICE=cuda

# Default number of speakers (host + guests)
DIARIZE_NUM_SPEAKERS=2

# ========================================
# File Paths
# ========================================
# Base directory for video processing
NEWSROOM_PATH=D:/newsroom

# Guest registry cache file
GUEST_REGISTRY_PATH=D:/newsroom/guest_registry.json

# ========================================
# Scoring Thresholds
# ========================================
# Minimum confidence score to publish (0.0-1.0)
MIN_PUBLISH_SCORE=0.60

# Minimum confidence for "Verified Expert" badge
MIN_EXPERT_SCORE=0.75

# ========================================
# API Rate Limiting
# ========================================
# Delay between Wikipedia/Wikidata API calls (seconds)
API_RATE_LIMIT_DELAY=0.5
