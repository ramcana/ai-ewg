# AI-EWG Pipeline Outputs Reference

Complete guide to all outputs generated by the AI-EWG video processing pipeline, their purposes, and storage locations.

---

## ðŸ“ Directory Structure Overview

```
data/
â”œâ”€â”€ audio/                    # Extracted audio files (WAV format)
â”œâ”€â”€ transcripts/             # Transcription outputs
â”‚   â”œâ”€â”€ txt/                # Plain text transcripts
â”‚   â””â”€â”€ vtt/                # WebVTT caption files
â”œâ”€â”€ enriched/               # AI enrichment data (JSON)
â”œâ”€â”€ outputs/                # Organized episode outputs
â”‚   â””â”€â”€ {show}/            # Show-specific folders
â”‚       â””â”€â”€ {year}/        # Year-based organization
â”‚           â””â”€â”€ {episode}/ # Episode folder
â”‚               â””â”€â”€ clips/ # Generated clips
â”œâ”€â”€ public/                 # Web-ready artifacts
â”‚   â”œâ”€â”€ shows/             # Episode HTML pages
â”‚   â”œâ”€â”€ assets/            # Public assets
â”‚   â”‚   â””â”€â”€ transcripts/  # Public transcript copies
â”‚   â””â”€â”€ meta/              # Episode metadata JSON
â”œâ”€â”€ social_packages/        # Social media packages
â”‚   â””â”€â”€ {episode_id}/      # Episode-specific packages
â”‚       â””â”€â”€ {platform}/    # Platform-specific content
â”œâ”€â”€ temp/                   # Temporary processing files
â”‚   â””â”€â”€ uploaded/          # User-uploaded files
â””â”€â”€ corrections/            # Learned corrections database
```

---

## ðŸŽ¯ Stage-by-Stage Outputs

### 1. **Media Preparation Stage**

**Purpose:** Extract audio from video and validate media properties

**Outputs:**
- **Audio File:** `data/audio/{episode_id}.wav`
  - Format: 16-bit PCM WAV
  - Sample rate: 16kHz (optimized for speech)
  - Channels: Mono
  - Purpose: Input for transcription stage

**Metadata Generated:**
- Duration (seconds)
- Bitrate
- Video codec
- Audio codec
- Resolution (e.g., "1920x1080")
- Frame rate (parsed safely with fractions.Fraction)

**Storage:** Temporary (can be cleaned up after transcription)

---

### 2. **Transcription Stage**

**Purpose:** Generate text transcripts and timed captions using Whisper AI

**Outputs:**

#### Plain Text Transcript
- **Location:** `data/transcripts/txt/{episode_id}.txt`
- **Format:** UTF-8 plain text
- **Content:** Full episode transcript
- **Purpose:** AI enrichment input, search indexing

#### WebVTT Captions
- **Location:** `data/transcripts/vtt/{episode_id}.vtt`
- **Format:** WebVTT (Web Video Text Tracks)
- **Content:** Timestamped captions with segments
- **Purpose:** Video subtitles, clip generation

**Database Storage:**
- Full transcript text
- Segments with timestamps
- Word-level timestamps (for clip generation)
- Detected language
- Translation status (if translated to English)
- Segment count, word count

**Features:**
- Multilingual support (10+ languages)
- Auto language detection
- Optional translation to English
- GPU acceleration (CUDA)
- Word-level timestamps for precise clip cutting

---

### 3. **Enrichment Stage**

**Purpose:** AI-powered content analysis and metadata extraction

**Outputs:**

#### Enrichment JSON
- **Location:** `data/enriched/{episode_id}.json`
- **Format:** JSON
- **Size:** Typically 50-200 KB

**Content Structure:**
```json
{
  "episode_id": "string",
  "show_name_extracted": "AI-extracted show name",
  "host_name_extracted": "AI-extracted host name",
  "transcript": {
    "text": "full transcript",
    "segments": []
  },
  "ai_analysis": {
    "executive_summary": "2-3 paragraph summary",
    "key_takeaways": ["5-7 key points"],
    "deep_analysis": "themes, implications, impact",
    "topics": ["8-10 topic tags"],
    "segment_titles": ["titles for transcript chunks"],
    "show_name": "extracted show name",
    "host_name": "extracted host name",
    "analysis_time": 0.0
  },
  "diarization": {
    "speakers": [],
    "segments": [],
    "num_speakers": 2,
    "validation": {},
    "consistency": {}
  },
  "entities": {
    "people": [],
    "organizations": [],
    "topics": []
  },
  "enriched_guests": [
    {
      "name": "string",
      "wikidata_id": "Q123456",
      "description": "string",
      "job_title": "string",
      "affiliation": "string",
      "authority_level": "expert|professional|public_figure",
      "proficiencyScore": 85,
      "credibilityBadge": "verified|credible|standard"
    }
  ],
  "proficiency_scores": {
    "scored_people": [],
    "summary": {}
  },
  "summary": {
    "key_takeaway": "string",
    "description": "string",
    "tags": []
  },
  "processing_time": 0.0,
  "ai_enhanced": true
}
```

**AI Features:**
- Executive summaries (Ollama LLM)
- Key takeaways extraction
- Deep thematic analysis
- Topic/keyword extraction
- Segment title generation
- Show name and host extraction
- Speaker diarization (pyannote.audio)
- Entity extraction (people, organizations)
- Wikidata disambiguation
- Proficiency scoring (credibility badges)
- Authority verification

**Database Storage:**
All enrichment data is saved to `episode.enrichment` field in database

---

### 4. **Rendering Stage**

**Purpose:** Generate web-ready artifacts and public assets

**Outputs:**

#### Episode HTML Page
- **Location:** `data/public/shows/{show_slug}/{episode_id}/index.html`
- **Format:** HTML5
- **Content:** AI-enhanced episode page with:
  - Episode metadata
  - Executive summary
  - Key takeaways
  - Topics/tags
  - Embedded video player
  - Interactive transcript
  - Guest information with badges

#### Episode Metadata JSON
- **Location:** `data/public/meta/{episode_id}.json`
- **Format:** JSON
- **Content:**
  ```json
  {
    "episode_id": "string",
    "metadata": {},
    "media": {},
    "transcripts": {
      "text": "/assets/transcripts/{episode_id}.txt",
      "vtt": "/assets/transcripts/{episode_id}.vtt"
    },
    "enrichment": {},
    "generated_at": "ISO 8601 timestamp"
  }
  ```

#### Public Transcript Copies
- **Location:** `data/public/assets/transcripts/`
  - `{episode_id}.txt` - Plain text
  - `{episode_id}.vtt` - WebVTT captions
- **Purpose:** Public web access, CDN distribution

---

## ðŸŽ¬ Clip Generation Outputs

### Clip Discovery & Storage

**Location:** `data/outputs/{show}/{year}/{episode}/clips/`

**Folder Structure:**
```
data/outputs/ForumDailyNews/2025/episode_folder/
â””â”€â”€ clips/
    â”œâ”€â”€ clip_{id}/
    â”‚   â”œâ”€â”€ 9x16_clean.mp4      # Vertical, no subtitles
    â”‚   â”œâ”€â”€ 9x16_subtitled.mp4  # Vertical, with subtitles
    â”‚   â”œâ”€â”€ 16x9_clean.mp4      # Horizontal, no subtitles
    â”‚   â””â”€â”€ 16x9_subtitled.mp4  # Horizontal, with subtitles
    â””â”€â”€ clip_{id2}/
        â””â”€â”€ ...
```

**Clip Metadata (Database):**
- Clip ID (UUID)
- Episode ID
- Start time (ms)
- End time (ms)
- Duration (ms)
- Topic/theme
- Virality score (0-100)
- Hook strength
- Engagement potential
- Status (pending/rendered/failed)
- Aspect ratios (9:16, 16:9, 1:1, 4:5)
- Variants (clean, subtitled)

**Clip Specifications:**
- **9:16 (Vertical):** TikTok, Instagram Reels, YouTube Shorts
- **16:9 (Horizontal):** YouTube, Facebook, X/Twitter
- **1:1 (Square):** Instagram Feed
- **4:5 (Portrait):** Instagram Feed, Facebook

**Subtitle Options:**
- **Clean:** No burned-in subtitles
- **Subtitled:** Burned-in SRT subtitles with styling

---

## ðŸ“± Social Media Packages

### Package Structure

**Location:** `data/social_packages/{episode_id}/{platform}/`

**Platforms Supported:**
- YouTube
- Instagram
- X (Twitter)
- TikTok
- Facebook

**Files Generated Per Platform:**

#### 1. Video File
- **Filename:** Platform-specific naming
  - YouTube: `{episode_id}_youtube.mp4`
  - Instagram: `{episode_id}_instagram.mp4`
  - TikTok: `{episode_id}_tiktok.mp4`
- **Format:** MP4 (H.264)
- **Specs:** Platform-optimized (resolution, duration, bitrate)

#### 2. Metadata Files
- **title.txt** - Platform-optimized title (character limits)
- **caption.txt** - Formatted caption with emojis
- **hashtags.txt** - Relevant hashtags (platform-specific limits)
- **description.txt** - Full description (YouTube, Facebook)

#### 3. Structured Data
- **structured_data.jsonld** - Schema.org JSON-LD for SEO
  - VideoObject schema
  - Person/Organization schemas
  - SeekToAction for Google Key Moments
  - Clip relationships (partOf)

#### 4. Package Metadata
- **metadata.json** - Complete package information
  ```json
  {
    "platform": "youtube",
    "episode_id": "string",
    "video_path": "path/to/video.mp4",
    "title": "string",
    "description": "string",
    "tags": [],
    "hashtags": [],
    "duration_seconds": 0,
    "resolution": "1920x1080",
    "aspect_ratio": "16:9",
    "file_size_mb": 0.0,
    "generated_at": "ISO 8601",
    "platform_requirements": {},
    "validation_results": {}
  }
  ```

**Platform Requirements:**
- **YouTube:** 16:9, max 10 min, chapter markers
- **Instagram Reels:** 9:16, max 90 sec
- **X/Twitter:** 16:9, max 2:20 min, 280 char caption
- **TikTok:** 9:16, max 3 min
- **Facebook:** 16:9, max 4 min

---

## ðŸ—„ï¸ Database Storage

### SQLite Database: `data/pipeline.db`

**Tables:**

#### episodes
- episode_id (PRIMARY KEY)
- source_path
- processing_stage
- metadata (JSON)
- transcription (JSON)
- enrichment (JSON)
- created_at
- updated_at
- errors (JSON)

#### clips
- clip_id (PRIMARY KEY)
- episode_id (FOREIGN KEY)
- start_ms
- end_ms
- duration_ms
- topic
- score
- status
- output_paths (JSON)
- created_at

#### processing_log
- log_id (PRIMARY KEY)
- episode_id (FOREIGN KEY)
- stage
- status
- message
- timestamp

#### social_jobs
- job_id (PRIMARY KEY)
- episode_id
- platforms (JSON)
- status
- progress
- packages_generated (JSON)
- errors (JSON)
- created_at
- completed_at

#### corrections
- correction_id (PRIMARY KEY)
- incorrect_text
- correct_text
- context
- show_name
- confidence
- applied_count
- created_at
- last_used_at

---

## ðŸ§¹ Temporary & Cache Files

### Temporary Files
- **Location:** `data/temp/`
- **Contents:**
  - Uploaded files (before processing)
  - Intermediate processing files
  - Temporary audio/video conversions
- **Cleanup:** Automatically cleaned after processing or on failure

### Cache Files
- **Streamlit Session State:**
  - `episodes_data` - Episode list cache
  - `file_cache` - File operation results
  - `api_cache` - API response cache
  - `clip_metadata_*` - Clip discovery results
- **TTL:** 1-3 minutes depending on operation
- **Cleanup:** Automatic expiration, manual clear available

---

## ðŸ“Š Output Size Estimates

### Per Episode (45-minute video):

| Output Type | Size | Notes |
|-------------|------|-------|
| Audio WAV | 80-120 MB | Temporary, can be deleted |
| Transcript TXT | 50-100 KB | Plain text |
| Transcript VTT | 100-200 KB | With timestamps |
| Enrichment JSON | 50-200 KB | AI analysis data |
| HTML Page | 50-150 KB | Web artifact |
| Metadata JSON | 20-50 KB | Episode metadata |
| **Per Clip** | | |
| 9:16 Clean (60s) | 8-15 MB | Vertical, no subs |
| 9:16 Subtitled (60s) | 9-18 MB | Vertical, with subs |
| 16:9 Clean (60s) | 10-20 MB | Horizontal, no subs |
| 16:9 Subtitled (60s) | 12-24 MB | Horizontal, with subs |
| **Social Package** | | |
| YouTube (10 min) | 80-150 MB | Full quality |
| Instagram Reel (90s) | 15-30 MB | Optimized |
| TikTok (3 min) | 25-50 MB | Optimized |

### Total Storage (per episode with 5 clips):
- **Core Processing:** ~200 MB (without source video)
- **Clips (5 Ã— 4 variants):** ~200-400 MB
- **Social Packages (5 platforms):** ~200-400 MB
- **Total:** ~600-1000 MB per fully processed episode

---

## ðŸ”„ Output Lifecycle

### Retention Policy

**Permanent Storage:**
- Transcripts (TXT, VTT)
- Enrichment JSON
- Episode metadata
- Database records
- Public web artifacts

**Temporary Storage (can be cleaned):**
- Audio WAV files (after transcription)
- Temp uploaded files (after processing)
- Cache files (auto-expire)

**Archival Candidates:**
- Clips older than 90 days (move to cold storage)
- Social packages after publishing (can be regenerated)

### Cleanup Mechanisms

**Automatic:**
- Session cache expiration (1-3 min TTL)
- Temp file cleanup on success/failure
- Old log rotation (30 days)

**Manual:**
- `clear_all_caches_and_state()` - Streamlit session state
- `cleanup_episode_files()` - Failed episode cleanup
- `cleanup_old_clips()` - Archive old clips

---

## ðŸ” Finding Outputs

### By Episode ID

```python
episode_id = "ForumDailyNews_ep140_2024-10-27"

# Transcripts
txt_path = f"data/transcripts/txt/{episode_id}.txt"
vtt_path = f"data/transcripts/vtt/{episode_id}.vtt"

# Enrichment
enrichment_path = f"data/enriched/{episode_id}.json"

# Web artifacts
html_path = f"data/public/shows/{show_slug}/{episode_id}/index.html"
meta_path = f"data/public/meta/{episode_id}.json"

# Clips (organized by show/year)
clips_dir = f"data/outputs/{show}/{year}/{episode_id}/clips/"

# Social packages
social_dir = f"data/social_packages/{episode_id}/"
```

### By Show Name

```python
# Using NamingService
from src.core.naming_service import NamingService

naming = NamingService()
episode_folder = naming.get_episode_folder_path(
    episode_id=episode_id,
    show_name="Forum Daily News",
    date=datetime.now(),
    base_path="data/outputs"
)
# Returns: data/outputs/ForumDailyNews/2025/episode_id/
```

---

## ðŸ“ Output Validation

### Quality Checks

**Transcripts:**
- âœ… File exists and is readable
- âœ… Non-empty content
- âœ… Valid UTF-8 encoding
- âœ… VTT format validation
- âœ… Word count > 100

**Enrichment:**
- âœ… Valid JSON structure
- âœ… Required fields present
- âœ… AI analysis completed
- âœ… Topics extracted (min 3)
- âœ… Summary generated

**Clips:**
- âœ… Video file exists
- âœ… Duration matches specification
- âœ… Resolution correct
- âœ… Aspect ratio correct
- âœ… Subtitles burned in (if subtitled variant)

**Social Packages:**
- âœ… All required files present
- âœ… Platform requirements met
- âœ… File size within limits
- âœ… Duration within limits
- âœ… Metadata complete

---

## ðŸš€ API Access

### Retrieve Outputs via API

```bash
# Get episode with all outputs
GET /episodes/{episode_id}

# List clips for episode
GET /clips/discover/{episode_id}

# Get clip metadata
GET /clips/{clip_id}

# List social packages
GET /social/packages/{episode_id}

# Get package details
GET /social/packages/{episode_id}/{platform}
```

---

## ðŸ“š Related Documentation

- [Cleanup Mechanism](./CLEANUP_MECHANISM.md)
- [Social Publishing Implementation](./SOCIAL_PUBLISHING_IMPLEMENTATION.md)
- [Multilingual Support](./MULTILINGUAL_SUPPORT.md)
- [Clip Generation Guide](./CLIP_GENERATION.md)
- [API Documentation](./API.md)

---

**Last Updated:** October 29, 2025  
**Pipeline Version:** 2.0  
**Maintained by:** AI-EWG Team
