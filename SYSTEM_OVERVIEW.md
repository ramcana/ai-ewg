# AI-EWG System Overview

## Architecture Summary

### **Backend (FastAPI)**
- **API Server**: `src/api/server.py` - RESTful API on port 8000
- **Database**: SQLite with WAL mode (`data/pipeline.db`)
- **Processing Pipeline**: `src/core/pipeline.py` - Stage-based orchestration
- **Job Queue**: Async processing with threading for long-running tasks
- **Endpoints**:
  - `/episodes` - Episode management (list, get, process, delete)
  - `/async/episodes/{id}/process` - Background processing
  - `/clips` - Clip discovery and rendering
  - `/social` - Social media package generation
  - `/health` - Health checks

### **Frontend (Streamlit)**
- **Main Dashboard**: `dashboard.py` - Multi-page navigation
- **Video Processing**: `components/processing.py` - File selection, batch processing
- **Job Monitor**: `pages/job_monitor.py` - Real-time progress tracking
- **Social Publishing**: `components/social_generator.py` - Platform package creation
- **Features**:
  - âœ… File selection with checkboxes (single/multiple)
  - âœ… Progress tracking with ETA
  - âœ… Failed episode management (retry/delete)
  - âœ… Smart discovery (skips duplicate checking for selected files)

---

## Processing Pipeline

### **Stage 1: Discovery & Prep**
```
Video File â†’ Discovery â†’ Database Registration â†’ Audio Extraction
```
- Scans organized input directories (see Input Structure below)
- Generates episode ID from filename and AI-extracted metadata
- Extracts audio for transcription

**Input Structure** (Organized by Show):
```
input_videos/
â”œâ”€â”€ TheNewsForum/
â”‚   â”œâ”€â”€ ForumDailyNews/      # Forum Daily News episodes
â”‚   â”œâ”€â”€ BoomAndBust/          # Boom and Bust episodes
â”‚   â”œâ”€â”€ CommunityProfile/     # Community Profile episodes
â”‚   â”œâ”€â”€ EconomicPulse/        # Economic Pulse episodes
â”‚   â””â”€â”€ FreedomForum/         # Freedom Forum episodes
â”œâ”€â”€ _uncategorized/           # Videos to be sorted later
â””â”€â”€ data/temp/uploaded/       # Temporary uploads from Streamlit
```

**Output Structure** (Consistent with Input):
```
data/
â”œâ”€â”€ clips/{episode_id}/clips/{clip_id}/    # Generated clips
â”œâ”€â”€ transcripts/{episode_id}/              # Transcription files
â”œâ”€â”€ enrichment/{episode_id}/               # AI analysis
â”œâ”€â”€ html/{episode_id}/                     # Web pages
â””â”€â”€ social_packages/{episode_id}/          # Platform packages
```

**Setup**: Run `.\setup_input_structure.ps1` to create input folders

### **Stage 2: Transcription (Whisper)**
```
Audio â†’ Whisper AI â†’ Transcript + Word Timestamps â†’ VTT/SRT
```
- Uses OpenAI Whisper (large-v3 model)
- Word-level timestamps for precise clip generation
- Diarization support (speaker identification)
- Outputs: JSON transcript, VTT, SRT subtitles

### **Stage 3: AI Enrichment (Ollama)**
```
Transcript â†’ Intelligence Chain â†’ Metadata Extraction â†’ Database
```

**Intelligence Chain Components** (`src/core/intelligence_chain_v2.py`):

1. **Entity Extraction**
   - Method: LLM (Ollama) or spaCy NLP
   - Extracts: People, organizations, locations, topics
   - Output: `entities.json`

2. **Disambiguation** (Wikidata API)
   - Resolves entities to Wikidata IDs
   - Enriches with: descriptions, images, URLs
   - Confidence scoring
   - Output: `enriched.json`

3. **Scoring & Ranking**
   - Proficiency scores for guests
   - Relevance ranking
   - Output: `scored.json`

4. **AI Analysis** (Ollama)
   - Show name, host name, episode number extraction
   - Executive summary generation
   - Key takeaways (bullet points)
   - Deep analysis
   - Topic extraction
   - Segment titles
   - Output: Stored in `episode.enrichment`

**Models Used**:
- LLM: `llama3.2:latest` (via Ollama)
- NLP: `en_core_web_lg` (spaCy)

---

## Social Media Generation

### **Platform Support**
- YouTube (16:9, 10 min max, chapter markers)
- Instagram Reels (9:16, 90 sec max)
- X/Twitter (16:9, 2:20 min max, 280 char)
- TikTok (9:16, 3 min max)
- Facebook (16:9, 4 min max)

### **Policy Engine** (`src/core/policy_engine.py`)
- Loads platform requirements from `config/platforms/*.yaml`
- Validates content against policies
- Transforms metadata (hashtags, descriptions, titles)
- Scoring system for policy compliance

### **Package Generator** (`src/core/package_generator.py`)
```
Episode â†’ Policy Validation â†’ Content Transformation â†’ Package Files
```

**Output Structure**: `data/social_packages/{episode_id}/{platform}/`
- `video.mp4` (platform-specific naming)
- `title.txt` (optimized for platform)
- `caption.txt` (with hashtags)
- `description.txt` (full description)
- `hashtags.txt` (platform-specific tags)
- `metadata.json` (comprehensive metadata)
- `structured_data.jsonld` (Schema.org for SEO)

### **Job Tracking** (`src/core/social_job_tracker.py`)
- Database: `social_jobs` table
- Real-time progress updates
- Per-platform error tracking
- Partial success support (some platforms succeed, others fail)

---

## Optimized Web Page + SEO

### **HTML Generation** (`src/stages/rendering_stage.py`)
```
Episode Data â†’ Jinja2 Templates â†’ Static HTML â†’ data/html/{episode_id}/
```

**Generated Pages**:
- `episode.html` - Full episode page with player, transcript, guests
- `show_index.html` - Show listing page
- `person_profile.html` - Guest profile pages

**SEO Features**:

1. **JSON-LD Structured Data** (`src/core/jsonld_generator.py`)
   - Schema.org VideoObject
   - Person/Organization schemas
   - SeekToAction for Google Key Moments
   - Breadcrumbs navigation
   - Embedded in HTML `<head>`

2. **Metadata Optimization**
   - AI-generated titles and descriptions
   - Keyword-rich content from topics
   - Open Graph tags for social sharing
   - Twitter Card metadata

3. **Content Structure**
   - Semantic HTML5 markup
   - Heading hierarchy (H1-H6)
   - Accessible ARIA labels
   - Mobile-responsive design

4. **Rich Snippets**
   - Video duration, upload date
   - Guest information with credentials
   - Topic tags and categories
   - Transcript excerpts

**Output**: `data/html/{episode_id}/episode.html`

---

## Data Flow Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Video File  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKEND PIPELINE (FastAPI + SQLite)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  1. Discovery â†’ Episode Registration                    â”‚
â”‚  2. Prep â†’ Audio Extraction                             â”‚
â”‚  3. Transcription â†’ Whisper AI â†’ Transcript + VTT       â”‚
â”‚  4. Enrichment â†’ Ollama + Wikidata â†’ Metadata           â”‚
â”‚  5. Rendering â†’ Jinja2 â†’ HTML + JSON-LD                 â”‚
â”‚  6. Clips â†’ Discovery + Rendering â†’ MP4 variants        â”‚
â”‚  7. Social â†’ Policy Engine â†’ Platform Packages          â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUTS                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ğŸ“ data/transcripts/{episode_id}/                      â”‚
â”‚     â”œâ”€â”€ transcript.json (full transcript)               â”‚
â”‚     â”œâ”€â”€ transcript.vtt (WebVTT subtitles)               â”‚
â”‚     â””â”€â”€ transcript.srt (SRT subtitles)                  â”‚
â”‚                                                          â”‚
â”‚  ğŸ“ data/enrichment/{episode_id}/                       â”‚
â”‚     â”œâ”€â”€ entities.json (extracted entities)              â”‚
â”‚     â”œâ”€â”€ enriched.json (Wikidata enrichment)             â”‚
â”‚     â””â”€â”€ scored.json (ranked guests)                     â”‚
â”‚                                                          â”‚
â”‚  ğŸ“ data/html/{episode_id}/                             â”‚
â”‚     â””â”€â”€ episode.html (SEO-optimized page + JSON-LD)     â”‚
â”‚                                                          â”‚
â”‚  ğŸ“ data/clips/{episode_id}/clips/{clip_id}/            â”‚
â”‚     â”œâ”€â”€ 9x16_clean.mp4 (vertical, no subs)              â”‚
â”‚     â”œâ”€â”€ 9x16_subtitled.mp4 (vertical, with subs)        â”‚
â”‚     â”œâ”€â”€ 16x9_clean.mp4 (horizontal, no subs)            â”‚
â”‚     â””â”€â”€ 16x9_subtitled.mp4 (horizontal, with subs)      â”‚
â”‚                                                          â”‚
â”‚  ğŸ“ data/social_packages/{episode_id}/                  â”‚
â”‚     â”œâ”€â”€ youtube/ (video + metadata + JSON-LD)           â”‚
â”‚     â”œâ”€â”€ instagram/ (9:16 video + caption + hashtags)    â”‚
â”‚     â”œâ”€â”€ twitter/ (video + 280 char + hashtags)          â”‚
â”‚     â”œâ”€â”€ tiktok/ (9:16 video + caption)                  â”‚
â”‚     â””â”€â”€ facebook/ (video + description)                 â”‚
â”‚                                                          â”‚
â”‚  ğŸ“ data/pipeline.db (SQLite database)                  â”‚
â”‚     â”œâ”€â”€ episodes (all episode data)                     â”‚
â”‚     â”œâ”€â”€ clips (clip specifications)                     â”‚
â”‚     â””â”€â”€ social_jobs (job tracking)                      â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND (Streamlit Dashboard)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ğŸ¬ Video Processing                                    â”‚
â”‚     â”œâ”€â”€ File selection (checkboxes)                     â”‚
â”‚     â”œâ”€â”€ Batch processing                                â”‚
â”‚     â”œâ”€â”€ Progress tracking                               â”‚
â”‚     â””â”€â”€ Failed episode management                       â”‚
â”‚                                                          â”‚
â”‚  ğŸ“Š Job Monitor                                         â”‚
â”‚     â”œâ”€â”€ Real-time status                                â”‚
â”‚     â”œâ”€â”€ Progress bars with ETA                          â”‚
â”‚     â””â”€â”€ Output preview                                  â”‚
â”‚                                                          â”‚
â”‚  ğŸ“± Social Publishing                                   â”‚
â”‚     â”œâ”€â”€ Platform selection                              â”‚
â”‚     â”œâ”€â”€ Package generation                              â”‚
â”‚     â””â”€â”€ Preview & download                              â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Technologies

### **AI/ML**
- **Whisper** (OpenAI) - Speech-to-text transcription
- **Ollama** (Llama 3.2) - Metadata extraction, summarization
- **spaCy** (en_core_web_lg) - NLP entity extraction
- **Wikidata API** - Entity disambiguation and enrichment

### **Backend**
- **FastAPI** - REST API framework
- **SQLite** - Database (WAL mode for concurrency)
- **Uvicorn** - ASGI server
- **Pydantic** - Data validation
- **Threading** - Background job processing

### **Frontend**
- **Streamlit** - Dashboard UI
- **Pandas** - Data display
- **Plotly** - Charts (if used)

### **Media Processing**
- **FFmpeg** - Video/audio manipulation
- **PyAV** - Python FFmpeg bindings
- **Pillow** - Image processing

### **Web Generation**
- **Jinja2** - HTML templating
- **JSON-LD** - Structured data (Schema.org)
- **Markdown** - Content formatting

---

## Recent Improvements

### **File Selection Fix**
- âœ… Added checkboxes for individual file selection
- âœ… Select All / Deselect All buttons
- âœ… Only processes selected files (not all discovered)

### **Discovery Optimization**
- âœ… Skips full directory scan when files are selected
- âœ… Loads existing episodes from database first
- âœ… Only runs discovery for missing files
- âœ… No more "Duplicate file detected" spam

### **Failed Episode Management**
- âœ… Delete button for failed episodes
- âœ… Bulk delete with confirmation
- âœ… Individual retry/delete per episode
- âœ… Complete cleanup (database + files + cache)

### **Resume Capability**
- âœ… Processing state stored in database
- âœ… Automatically resumes from last completed stage
- âœ… No need to reprocess completed stages
- âœ… Force reprocess option available

---

## Configuration

### **Main Config**: `config/pipeline.yaml`
```yaml
# Organized input sources by show
sources:
  - path: "input_videos/TheNewsForum/ForumDailyNews"
    enabled: true
  - path: "input_videos/TheNewsForum/BoomAndBust"
    enabled: true
  - path: "input_videos/TheNewsForum/CommunityProfile"
    enabled: true
  - path: "input_videos/TheNewsForum/EconomicPulse"
    enabled: true
  - path: "input_videos/TheNewsForum/FreedomForum"
    enabled: true
  - path: "input_videos/_uncategorized"
    enabled: true
  - path: "data/temp/uploaded"
    enabled: true
  # Legacy folder (disabled)
  - path: "test_videos/newsroom/2024"
    enabled: false

models:
  whisper_model: large-v3
  llm: llama3.2:latest
  spacy_model: en_core_web_lg

clip_generation:
  enabled: true
  min_duration: 30
  max_duration: 180

# Episode naming and organization
organization:
  folder_structure: "{show_folder}/{year}"
  episode_template: "{show_folder}_ep{episode_number}_{date}"
```

### **Platform Configs**: `config/platforms/*.yaml`
- `youtube.yaml` - YouTube requirements
- `instagram.yaml` - Instagram Reels specs
- `tiktok.yaml` - TikTok requirements
- `twitter.yaml` - X/Twitter specs
- `facebook.yaml` - Facebook requirements

---

## Startup Commands

### **Start Backend API**
```powershell
.\start-api-server.ps1
# Runs on http://localhost:8000
```

### **Start Frontend Dashboard**
```powershell
streamlit run dashboard.py
# Runs on http://localhost:8501
```

### **Check Health**
```powershell
curl http://localhost:8000/health
```

---

## API Endpoints Quick Reference

### **Episodes**
- `GET /episodes` - List all episodes
- `GET /episodes/{id}` - Get episode details
- `POST /episodes/discover` - Discover new episodes
- `POST /episodes/{id}/process` - Process episode (sync)
- `DELETE /episodes/{id}` - Delete episode

### **Async Processing**
- `POST /async/episodes/{id}/process` - Start background job
- `GET /async/jobs/{id}` - Get job status
- `GET /async/jobs` - List all jobs

### **Clips**
- `POST /clips/discover/{episode_id}` - Discover clips
- `POST /clips/render/{episode_id}` - Render clips
- `GET /clips/{episode_id}` - List episode clips

### **Social Media**
- `POST /social/generate` - Generate packages (returns job_id)
- `GET /social/jobs/{job_id}` - Get generation status
- `GET /social/platforms` - List supported platforms
- `GET /social/packages/{episode_id}` - List packages

---

## Performance Characteristics

### **Processing Times** (10-minute video)
- Discovery: ~1 second
- Audio Extraction: ~5 seconds
- Transcription (Whisper): ~2-3 minutes
- Enrichment (AI): ~30-60 seconds
- HTML Generation: ~2 seconds
- Clip Discovery: ~10-15 seconds
- Social Packages: ~5-10 seconds per platform

### **Resource Usage**
- CPU: High during transcription (Whisper)
- GPU: Used if available (RTX 4080 detected)
- RAM: ~4-8 GB during processing
- Disk: ~500 MB per 10-minute episode (all outputs)

### **Scalability**
- Single-worker mode (SQLite limitation)
- Sequential processing (one episode at a time)
- Background jobs for long operations
- PostgreSQL migration available for production

---

## Next Steps / Future Enhancements

### **Planned**
- [ ] Direct platform publishing (YouTube, Instagram APIs)
- [ ] Video transcoding for platform requirements
- [ ] Thumbnail generation with AI
- [ ] Analytics and performance tracking
- [ ] Multi-language support
- [ ] PostgreSQL migration for production

### **In Progress**
- [x] File selection UI
- [x] Discovery optimization
- [x] Failed episode management
- [x] Resume capability

---

**Last Updated**: October 27, 2025  
**Version**: 1.0  
**Status**: Production-Ready
